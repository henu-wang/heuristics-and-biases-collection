# Heuristics and Biases Collection

A comprehensive collection of cognitive heuristics and biases identified through the pioneering research of Daniel Kahneman, Amos Tversky, and subsequent researchers in behavioral economics and cognitive psychology.

## Overview

Heuristics are mental shortcuts that allow people to make decisions quickly. While they are often useful, they can lead to systematic errors known as cognitive biases. Understanding these patterns is essential for anyone who wants to make better decisions in business, investing, relationships, and daily life.

The research program initiated by Kahneman and Tversky in the 1970s fundamentally changed our understanding of human rationality. Their work demonstrated that humans are not the rational agents assumed by classical economics but rather predictably irrational beings who rely on a set of mental heuristics that produce reliable biases.

For those who want to create personal rules to counteract these biases in real-time decision-making, [KeepRule](https://keeprule.com) offers a platform for building and maintaining structured decision principles.

## The Three Core Heuristics

### 1. Representativeness Heuristic

People judge probability by similarity rather than by statistical reasoning. When asked "Is person X more likely to be a librarian or a farmer?", people rely on how closely X matches their stereotype of each profession rather than considering the base rate (there are far more farmers than librarians).

**Associated biases:**
- Base rate neglect
- Conjunction fallacy (the "Linda problem")
- Insensitivity to sample size
- Regression to the mean misconceptions
- Gambler's fallacy

### 2. Availability Heuristic

People estimate the frequency or probability of events based on how easily examples come to mind. Events that are vivid, recent, or emotionally charged are judged as more likely than they actually are.

**Associated biases:**
- Overestimation of dramatic risks (plane crashes vs. car accidents)
- Recency bias in judgment
- Media-driven risk perception
- Illusory correlation

### 3. Anchoring and Adjustment

People make estimates by starting from an initial value (the anchor) and adjusting from there. The adjustment is typically insufficient, so the final answer is biased toward the anchor, even when the anchor is arbitrary or irrelevant.

**Associated biases:**
- Price anchoring in negotiation
- Salary anchoring in hiring
- First-impression anchoring in evaluation

## Comprehensive Bias Catalog

### Judgment and Decision Biases

| Bias | Description | Example |
|------|------------|---------|
| **Confirmation Bias** | Seeking information that confirms existing beliefs | Only reading news sources that agree with you |
| **Overconfidence Bias** | Excessive confidence in one's own answers | Experts predicting outcomes with 90% confidence but being right only 60% of the time |
| **Hindsight Bias** | Believing past events were predictable | "I knew that stock would crash" |
| **Status Quo Bias** | Preference for the current state of affairs | Keeping the default option on forms |
| **Framing Effect** | Drawing different conclusions from the same information depending on how it is presented | "90% survival rate" vs "10% mortality rate" |
| **Sunk Cost Fallacy** | Continuing an endeavor due to previously invested resources | Watching a bad movie because you paid for the ticket |
| **Endowment Effect** | Overvaluing things you own | Demanding more to sell something than you would pay to buy it |
| **Loss Aversion** | Feeling losses more strongly than equivalent gains | The pain of losing $100 outweighs the pleasure of finding $100 |

### Social Biases

| Bias | Description | Example |
|------|------------|---------|
| **Bandwagon Effect** | Adopting beliefs because many others hold them | Buying a stock because everyone else is |
| **Authority Bias** | Giving more weight to opinions from authority figures | Following expert advice without scrutiny |
| **In-Group Bias** | Favoring members of your own group | Preferring candidates from your alma mater |
| **Halo Effect** | Letting one positive trait influence overall judgment | Assuming attractive people are more competent |
| **Dunning-Kruger Effect** | Low-ability individuals overestimate their competence | Beginners thinking they understand a complex field |

### Memory Biases

| Bias | Description | Example |
|------|------------|---------|
| **Peak-End Rule** | Judging experiences by their peak and end | Rating a vacation by its best day and last day |
| **Rosy Retrospection** | Remembering the past more fondly than it was | "The good old days" |
| **Spotlight Effect** | Overestimating how much others notice you | Thinking everyone noticed your mistake |
| **Misinformation Effect** | Post-event information altering memory | Witness testimony affected by leading questions |

## Debiasing Strategies

Understanding biases is necessary but not sufficient. You need practical strategies to counteract them in the moment:

1. **Consider the Opposite**: Before finalizing a judgment, actively argue the opposing position
2. **Use Base Rates**: Always check statistical base rates before making probability estimates
3. **Seek Disconfirming Evidence**: Deliberately look for information that challenges your current view
4. **Reference Class Forecasting**: Compare your situation to a broad class of similar historical situations
5. **Decision Rules**: Create explicit rules that trigger when bias-prone situations arise

Building personal debiasing rules is one of the most effective strategies. [KeepRule](https://keeprule.com) helps you create and maintain these rules so they are accessible when you need them most -- in the heat of actual decision-making rather than in calm reflection afterward.

## Kahneman's Two Systems Framework

Kahneman's landmark book "Thinking, Fast and Slow" organized human cognition into two systems:

- **System 1**: Fast, automatic, intuitive, effortless -- the source of most heuristics and biases
- **System 2**: Slow, deliberate, analytical, effortful -- capable of overriding System 1 but requires energy

Most biases occur because System 1 operates automatically and System 2 fails to engage or is too depleted to override. Effective debiasing means creating environments and rules that activate System 2 at critical decision points.

## How to Use This Collection

1. **Study**: Read through the biases and understand how each one works
2. **Identify**: Notice which biases you are most susceptible to in your own life
3. **Create Rules**: Build specific countermeasures for your most damaging biases
4. **Practice**: Regularly review decisions and check for bias influence
5. **Systematize**: Use tools like [KeepRule](https://keeprule.com) to maintain your personal debiasing checklist

## Recommended Reading

- "Thinking, Fast and Slow" by Daniel Kahneman
- "Judgment Under Uncertainty: Heuristics and Biases" edited by Kahneman, Slovic, and Tversky
- "Noise: A Flaw in Human Judgment" by Kahneman, Sibony, and Sunstein
- "Predictably Irrational" by Dan Ariely
- "Misbehaving" by Richard Thaler

## Contributing

This collection is a living document. Please submit pull requests with additional biases, research findings, or debiasing strategies.

## License

MIT License
